{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Price Prediction with Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  This dataset was collected from kaggle and is collection of 79 explanatory variables (features) describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home. It has consists of 2919 records (rows) and 81 features(columns).\n",
    "\n",
    "#### Our objective is to predict house prices using one basic machine learning algorithm, Linear Regression. We will also use regression with regularization such as Ridge and Lasso to try to improve our prediction accuracy. \n",
    "\n",
    "#### Note: This is a continuation of our previous data analysis. We have already performed data wrangling, cleaning, EDA and feature selection and are ready for the next step i.e. Modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Necessary Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('linear_regression_train.csv')\n",
    "df_test = pd.read_csv('linear_regression_test.csv')\n",
    "\n",
    "features = list(df_train.drop(columns = 'LogSalePrice').columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Train-Test Split dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before we can start modelling the data, we need to confirm that our dataset is split into training and test sets. We will train the models with the training set and predict with the test set. Furthermore, we can use cross validation on our test set when performing regulariztion techniques.\n",
    "#### It is very important for the data to be split into training and test sets to prevent any data leakage. Here as our data is already split, we will then separate outcome and explanatory variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating outcome and explanatory variables into their resp. datasets\n",
    "\n",
    "X_train = pd.DataFrame(df_train[features])\n",
    "y_train = pd.DataFrame(df_train['LogSalePrice'])\n",
    "X_test = pd.DataFrame(df_test[features])\n",
    "y_test = pd.DataFrame(df_test['LogSalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only numeric variables for scaling i.e. without OHE variables\n",
    "\n",
    "scale_features = set(features) - set([ 'GarageType_2Types', 'GarageType_Attchd', 'GarageType_Basment',\n",
    " 'GarageType_BuiltIn', 'GarageType_CarPort', 'GarageType_Detchd', 'SaleCondition_Abnorml',\n",
    " 'SaleCondition_AdjLand', 'SaleCondition_Alloca', 'SaleCondition_Family', 'SaleCondition_Normal',\n",
    " 'SaleCondition_Partial'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling (MinMax Transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We know our dataset is skewed and also has a number of outliers left in our features, hence we will apply Robust scaling to normalize the data features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RobustScaler()\n",
    "rs.fit(X_train[scale_features])    \n",
    "X_train = rs.transform(X_train[scale_features])\n",
    "X_test = rs.transform(X_test[scale_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1455.000000</td>\n",
       "      <td>1455.000000</td>\n",
       "      <td>1455.000000</td>\n",
       "      <td>1455.000000</td>\n",
       "      <td>1455.000000</td>\n",
       "      <td>1455.000000</td>\n",
       "      <td>1455.000000</td>\n",
       "      <td>1455.000000</td>\n",
       "      <td>1455.000000</td>\n",
       "      <td>1455.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1455.000000</td>\n",
       "      <td>1455.000000</td>\n",
       "      <td>1455.000000</td>\n",
       "      <td>1455.000000</td>\n",
       "      <td>1455.000000</td>\n",
       "      <td>1455.000000</td>\n",
       "      <td>1455.000000</td>\n",
       "      <td>1455.000000</td>\n",
       "      <td>1455.000000</td>\n",
       "      <td>1455.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.125239</td>\n",
       "      <td>0.700417</td>\n",
       "      <td>0.383505</td>\n",
       "      <td>-0.175322</td>\n",
       "      <td>-0.143335</td>\n",
       "      <td>-0.134021</td>\n",
       "      <td>0.018590</td>\n",
       "      <td>-0.037816</td>\n",
       "      <td>0.478255</td>\n",
       "      <td>-0.392440</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125182</td>\n",
       "      <td>0.417978</td>\n",
       "      <td>-0.436426</td>\n",
       "      <td>0.039145</td>\n",
       "      <td>0.026291</td>\n",
       "      <td>-0.224690</td>\n",
       "      <td>-0.233677</td>\n",
       "      <td>0.434137</td>\n",
       "      <td>-0.041458</td>\n",
       "      <td>-0.410879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.839946</td>\n",
       "      <td>1.729798</td>\n",
       "      <td>0.503088</td>\n",
       "      <td>1.080718</td>\n",
       "      <td>1.532272</td>\n",
       "      <td>0.816300</td>\n",
       "      <td>0.089414</td>\n",
       "      <td>0.657316</td>\n",
       "      <td>0.505739</td>\n",
       "      <td>0.638579</td>\n",
       "      <td>...</td>\n",
       "      <td>1.151036</td>\n",
       "      <td>0.513648</td>\n",
       "      <td>0.551271</td>\n",
       "      <td>0.161960</td>\n",
       "      <td>0.408794</td>\n",
       "      <td>0.508096</td>\n",
       "      <td>0.748474</td>\n",
       "      <td>0.499667</td>\n",
       "      <td>0.732253</td>\n",
       "      <td>1.446801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.991952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.170639</td>\n",
       "      <td>-16.111618</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>-2.195652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.632837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.769489</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.249866</td>\n",
       "      <td>-4.813013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.392354</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.564281</td>\n",
       "      <td>-0.467817</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.413043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.531291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.769489</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.566359</td>\n",
       "      <td>-0.593842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.607646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.435719</td>\n",
       "      <td>0.532183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.468709</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.433641</td>\n",
       "      <td>0.406158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.458753</td>\n",
       "      <td>6.315358</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.148223</td>\n",
       "      <td>12.128781</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>1.316713</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.696462</td>\n",
       "      <td>1.441655</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>6.605298</td>\n",
       "      <td>0.719911</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.158032</td>\n",
       "      <td>2.572957</td>\n",
       "      <td>1.231924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  1455.000000  1455.000000  1455.000000  1455.000000  1455.000000   \n",
       "mean      0.125239     0.700417     0.383505    -0.175322    -0.143335   \n",
       "std       0.839946     1.729798     0.503088     1.080718     1.532272   \n",
       "min      -1.991952     0.000000     0.000000    -7.170639   -16.111618   \n",
       "25%      -0.392354     0.000000     0.000000    -0.564281    -0.467817   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.607646     0.000000     1.000000     0.435719     0.532183   \n",
       "max       4.458753     6.315358     2.000000     4.148223    12.128781   \n",
       "\n",
       "                5            6            7            8            9   ...  \\\n",
       "count  1455.000000  1455.000000  1455.000000  1455.000000  1455.000000  ...   \n",
       "mean     -0.134021     0.018590    -0.037816     0.478255    -0.392440  ...   \n",
       "std       0.816300     0.089414     0.657316     0.505739     0.638579  ...   \n",
       "min      -3.000000    -0.693147    -2.195652     0.000000    -1.000000  ...   \n",
       "25%      -1.000000     0.000000    -0.413043     0.000000    -1.000000  ...   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "75%       0.000000     0.000000     0.586957     1.000000     0.000000  ...   \n",
       "max       5.000000     0.693147     0.804348     1.316713     2.000000  ...   \n",
       "\n",
       "                20           21           22           23           24  \\\n",
       "count  1455.000000  1455.000000  1455.000000  1455.000000  1455.000000   \n",
       "mean     -0.125182     0.417978    -0.436426     0.039145     0.026291   \n",
       "std       1.151036     0.513648     0.551271     0.161960     0.408794   \n",
       "min      -4.632837     0.000000    -2.000000     0.000000     0.000000   \n",
       "25%      -0.531291     0.000000    -1.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.468709     1.000000     0.000000     0.000000     0.000000   \n",
       "max       4.696462     1.441655     1.000000     1.098612     6.605298   \n",
       "\n",
       "                25           26           27           28           29  \n",
       "count  1455.000000  1455.000000  1455.000000  1455.000000  1455.000000  \n",
       "mean     -0.224690    -0.233677     0.434137    -0.041458    -0.410879  \n",
       "std       0.508096     0.748474     0.499667     0.732253     1.446801  \n",
       "min      -0.769489    -2.000000     0.000000    -3.249866    -4.813013  \n",
       "25%      -0.769489    -1.000000     0.000000    -0.566359    -0.593842  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.230511     0.000000     1.000000     0.433641     0.406158  \n",
       "max       0.719911     2.000000     1.158032     2.572957     1.231924  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will build four models and evaluate their performances with R-squared metric. Additionally, we will gain insights on the features that are strong predictors of house prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.2313391 ],\n",
       "       [12.28313879],\n",
       "       [12.1464138 ],\n",
       "       ...,\n",
       "       [11.80869761],\n",
       "       [11.91590374],\n",
       "       [11.52882309]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted values\n",
    "\n",
    "yr_hat = lr.predict(X_test)\n",
    "yr_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8352608416622371\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the algorithm with the test set \n",
    "\n",
    "lr_score = lr.score(X_test, y_test) \n",
    "print(\"Accuracy: \", lr_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We note our basic Linear Regression performed quite well.\n",
    "#### Note: Our linear regression performs gradient descent under the hood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results:  [0.85110989 0.83913766 0.85731319 0.85012893 0.83686478]\n",
      "R2:  0.8469108918952589\n"
     ]
    }
   ],
   "source": [
    "# cross validation to find 'validate' score across multiple samples, automatically does Kfold stratifying\n",
    "\n",
    "lr_cv = cross_val_score(lr, X_train, y_train, cv = 5, scoring= 'r2')\n",
    "print(\"Cross-validation results: \", lr_cv)\n",
    "print(\"R2: \", lr_cv.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't appear that for this train-test dataset, the model is not over-fitting the data (the cross-validation performance is very close in value). It may be a slightly over-fitted but we can't really tell by the R-squared metric alone. If it is over-fitted, we can do some data transforms or feature engineering to improve its performance. But our main objective initially is to spot-check a few algorithms and fine tune the model later on. \n",
    "\n",
    "To help prevent over-fitting in which may result from simple linear regression, we can use regression models with regularization. Let's look at ridge and lasso next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The alpha parameter in ridge and lasso regularizes the regression model. The regression algorithms with regularization differ from linear regression in that they try to penalize those features that are not significant in our prediction. Ridge will try to reduce their effects (i.e., shrink their coeffients) in order to optimize all the input features. Lasso will try to remove the not-significant features by making their coefficients zero. In short, Lasso (L1 regularization) can eliminate the not-significant features, thus performing feature selection while Ridge (L2 regularization) cannot.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results:  [0.85167273 0.83869145 0.8570851  0.85018822 0.83686158]\n",
      "R2:  0.8468998158408972\n"
     ]
    }
   ],
   "source": [
    "# set alpha to a default value of 1 as baseline  \n",
    "\n",
    "ridge = Ridge(alpha = 1)  \n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "ridge_cv = cross_val_score(ridge, X_train, y_train, cv = 5, scoring = 'r2')\n",
    "print (\"Cross-validation results: \", ridge_cv)\n",
    "print (\"R2: \", ridge_cv.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results:  [0.85310785 0.83912763 0.85520906 0.84922742 0.84087026]\n",
      "R2:  0.8475084449253029\n"
     ]
    }
   ],
   "source": [
    "# set alpha to almost zero as baseline\n",
    "\n",
    "lasso = Lasso(alpha = .001)  \n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "lasso_cv = cross_val_score(lasso, X_train, y_train, cv = 5, scoring = 'r2')\n",
    "print (\"Cross-validation results: \", lasso_cv)\n",
    "print (\"R2: \", lasso_cv.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: Alpha is the regularization parameter. The alpha values chosen for ridge and lasso serve as a starting point and are not likely the best. To determine the best alpha for the model, we can use GridSearch. We would feed GridSearch a range of alpha values and it will try them all in cross-validation to output the best one for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We performed a basic Linear Regression model first and it performed quite well, with an accuracy score of 0.9 on our test set.\n",
    "#### We further checked lasso and ridge regression with just 1 value as baseline and they performance was almost similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suggestion for Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Data preprocessing. Try different types of data transfoms to expose the data structure better, so we may be able to improve model accuracy\n",
    "* Checking different limits for collinearty when removing features. \n",
    "* Use VIF to detect collinearity in Simple Linear Regression model\n",
    "* Use of dimensionality reducing techniques(e.g. - PCA, Isolation Forest,) to detect and remove collinear features (This will take away our ability to make inference from the data but can help in increasing prediction score) \n",
    "* Try different scalers for better performance\n",
    "* Try Polynomial model for prediction\n",
    "* Try Generalized Linear Models for prediction\n",
    "* Try GridSearch to identify optimal parameters. \n",
    "* Try other models like KNN,Random Forest,SVM etc and fine tune the models with ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
